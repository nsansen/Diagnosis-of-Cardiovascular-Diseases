{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Softmax, Add, Flatten, Activation# , Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  # DATA ACQUISITION *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"C:/Users/nisch/Desktop/ECG Categorization\\DATASET\\mitbih_test.csv\", header=None);\n",
    "train = pd.read_csv(\"C:/Users/nisch/Desktop/ECG Categorization\\DATASET\\mitbih_train.csv\", header=None);\n",
    "mit_train_data = train\n",
    "mit_test_data = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRODUCE BALANCED DATASET train_df , test_df *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisch\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\nisch\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\nisch\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\nisch\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\nisch\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    20000\n",
      "3.0    20000\n",
      "4.0    20000\n",
      "2.0    20000\n",
      "0.0    20000\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# There is a huge difference in the balanced of the classes.\n",
    "# Better choose the resample technique more than the class weights for the algorithms.\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_1=mit_train_data[mit_train_data[187]==1]\n",
    "df_2=mit_train_data[mit_train_data[187]==2]\n",
    "df_3=mit_train_data[mit_train_data[187]==3]\n",
    "df_4=mit_train_data[mit_train_data[187]==4]\n",
    "df_0=(mit_train_data[mit_train_data[187]==0]).sample(n=20000,random_state=42)\n",
    "\n",
    "df_1_upsample=resample(df_1,replace=True,n_samples=20000,random_state=123)\n",
    "df_2_upsample=resample(df_2,replace=True,n_samples=20000,random_state=124)\n",
    "df_3_upsample=resample(df_3,replace=True,n_samples=20000,random_state=125)\n",
    "df_4_upsample=resample(df_4,replace=True,n_samples=20000,random_state=126)\n",
    "\n",
    "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])\n",
    "\n",
    "\n",
    "df_11=mit_test_data[mit_train_data[187]==1]\n",
    "df_22=mit_test_data[mit_train_data[187]==2]\n",
    "df_33=mit_test_data[mit_train_data[187]==3]\n",
    "df_44=mit_test_data[mit_train_data[187]==4]\n",
    "df_00=(mit_test_data[mit_train_data[187]==0]).sample(n=20000,random_state=42)\n",
    "\n",
    "df_11_upsample=resample(df_1,replace=True,n_samples=20000,random_state=123)\n",
    "df_22_upsample=resample(df_2,replace=True,n_samples=20000,random_state=124)\n",
    "df_33_upsample=resample(df_3,replace=True,n_samples=20000,random_state=125)\n",
    "df_44_upsample=resample(df_4,replace=True,n_samples=20000,random_state=126)\n",
    "\n",
    "test_df=pd.concat([df_00,df_11_upsample,df_22_upsample,df_33_upsample,df_44_upsample])\n",
    "\n",
    "\n",
    "equilibre=train_df[187].value_counts()\n",
    "print(equilibre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Train data\n",
      "Type\tCount\n",
      "0.0    72471\n",
      "4.0     6431\n",
      "2.0     5788\n",
      "1.0     2223\n",
      "3.0      641\n",
      "Name: 187, dtype: int64\n",
      "-------------------------\n",
      "ALL Test data\n",
      "Type\tCount\n",
      "0.0    18118\n",
      "4.0     1608\n",
      "2.0     1448\n",
      "1.0      556\n",
      "3.0      162\n",
      "Name: 187, dtype: int64\n",
      "ALL Balanced Train data\n",
      "Type\tCount\n",
      "1.0    20000\n",
      "3.0    20000\n",
      "4.0    20000\n",
      "2.0    20000\n",
      "0.0    20000\n",
      "Name: 187, dtype: int64\n",
      "-------------------------\n",
      "ALL Balanced Test data\n",
      "Type\tCount\n",
      "1.0    20000\n",
      "3.0    20000\n",
      "4.0    20000\n",
      "2.0    20000\n",
      "0.0    20000\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"ALL Train data\")\n",
    "print(\"Type\\tCount\")\n",
    "print((mit_train_data[187]).value_counts())\n",
    "print(\"-------------------------\")\n",
    "print(\"ALL Test data\")\n",
    "print(\"Type\\tCount\")\n",
    "print((mit_test_data[187]).value_counts())\n",
    "\n",
    "print(\"ALL Balanced Train data\")\n",
    "print(\"Type\\tCount\")\n",
    "print((train_df[187]).value_counts())\n",
    "print(\"-------------------------\")\n",
    "print(\"ALL Balanced Test data\")\n",
    "print(\"Type\\tCount\")\n",
    "print((train_df[187]).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE HOT Encoding *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for categorical target\n",
    "#Since we will be using neural networks for our classification model, \n",
    "#our output classes need to be turned into a numerical representation. We use one hot encoding (from sklearn package) to do this.\n",
    "\n",
    "\n",
    "\n",
    "#train_target = mit_train_data[187]\n",
    "#train_target = train_target.values.reshape(87554,1)\n",
    "train_target = train_df[187]\n",
    "train_target = train_target.values.reshape(100000,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#one hot encode train_target\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "# TODO: create a OneHotEncoder object, and fit it to all of X\n",
    "\n",
    "# 1. INSTANTIATE\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(train_target)\n",
    "\n",
    "# 3. Transform\n",
    "onehotlabels = enc.transform(train_target).toarray()\n",
    "onehotlabels.shape\n",
    "\n",
    "target = onehotlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 187, 1)\n",
      "(75000, 5)\n"
     ]
    }
   ],
   "source": [
    "#remove ground truth labels from training df\n",
    "#train/test split\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = mit_train_data\n",
    "X = train_df\n",
    "X = X.drop(axis=1,columns=187)\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,target, test_size = 0.25, random_state = 36)\n",
    "X_train = np.asarray(X_train)\n",
    "X_valid = np.asarray(X_valid)\n",
    "Y_train = np.asarray(Y_train)\n",
    "Y_valid = np.asarray(Y_valid)\n",
    "\n",
    "#X_train.reshape((1, 2403, 187))\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid = np.expand_dims(X_valid, axis=2)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "# 2,403 training heartbeats and 802 validation heartbeats \n",
    "# for a 75:25 train-test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 MODEL NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- X ---\n",
      "            0         1         2         3         4         5         6    \\\n",
      "10153  0.162791  0.540698  0.755814  0.186047  0.168605  0.546512  0.616279   \n",
      "33886  0.990066  0.938742  0.344371  0.034768  0.273179  0.331126  0.326159   \n",
      "32005  0.974239  0.932084  0.590164  0.131148  0.014052  0.168618  0.238876   \n",
      "56159  0.978495  0.723118  0.526882  0.298387  0.220430  0.158602  0.091398   \n",
      "61783  0.963351  0.709424  0.060209  0.013089  0.057592  0.041885  0.047120   \n",
      "\n",
      "            7         8         9    ...  177  178  179  180  181  182  183  \\\n",
      "10153  0.697674  0.651163  0.703488  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "33886  0.341060  0.347682  0.347682  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "32005  0.210773  0.196721  0.208431  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "56159  0.091398  0.080645  0.083333  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "61783  0.034031  0.039267  0.044503  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       184  185  186  \n",
      "10153  0.0  0.0  0.0  \n",
      "33886  0.0  0.0  0.0  \n",
      "32005  0.0  0.0  0.0  \n",
      "56159  0.0  0.0  0.0  \n",
      "61783  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 187 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 10153 to 86696\n",
      "Columns: 187 entries, 0 to 186\n",
      "dtypes: float64(187)\n",
      "memory usage: 143.4 MB\n",
      "None\n",
      "--- Y ---\n",
      "--- testX ---\n",
      "            0         1         2         3         4         5         6    \\\n",
      "17155  0.966581  0.802057  0.077121  0.000000  0.161954  0.244216  0.254499   \n",
      "8157   1.000000  0.644444  0.031111  0.026667  0.151111  0.128889  0.080000   \n",
      "3635   1.000000  0.965318  0.734104  0.462428  0.271676  0.156069  0.150289   \n",
      "19125  1.000000  0.998792  0.960145  0.896135  0.898551  0.873188  0.766908   \n",
      "3002   0.009836  0.000000  0.163934  0.242623  0.327869  0.350820  0.331148   \n",
      "\n",
      "            7         8         9    ...  177  178  179  180  181  182  183  \\\n",
      "17155  0.262211  0.264782  0.272494  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "8157   0.080000  0.084444  0.080000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3635   0.173410  0.173410  0.150289  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "19125  0.591787  0.327295  0.252415  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3002   0.331148  0.354098  0.373771  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       184  185  186  \n",
      "17155  0.0  0.0  0.0  \n",
      "8157   0.0  0.0  0.0  \n",
      "3635   0.0  0.0  0.0  \n",
      "19125  0.0  0.0  0.0  \n",
      "3002   0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 187 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 17155 to 86696\n",
      "Columns: 187 entries, 0 to 186\n",
      "dtypes: float64(187)\n",
      "memory usage: 143.4 MB\n",
      "None\n",
      "--- testy ---\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1 https://www.kaggle.com/freddycoder/heartbeat-categorization\n",
    "# Separate features and targets\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print(\"--- X ---\")\n",
    "# X = mit_train_data.loc[:, mit_train_data.columns != 187]\n",
    "X = train_df.loc[:, mit_train_data.columns != 187]\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "\n",
    "print(\"--- Y ---\")\n",
    "# y = mit_train_data.loc[:, mit_train_data.columns == 187]\n",
    "y = train_df.loc[:, mit_train_data.columns == 187]\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(\"--- testX ---\")\n",
    "#testX = mit_test_data.loc[:, mit_test_data.columns != 187]\n",
    "testX = test_df.loc[:, mit_test_data.columns != 187]\n",
    "print(testX.head())\n",
    "print(testX.info())\n",
    "\n",
    "print(\"--- testy ---\")\n",
    "#testy = mit_test_data.loc[:, mit_test_data.columns == 187]\n",
    "testy = test_df.loc[:, mit_test_data.columns == 187]\n",
    "testy = to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model to make prediction\n",
    "\n",
    "#The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
    "#The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters.\n",
    "# softmax is used to categorize \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, activation='relu', input_shape=(187,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=2,verbose=1 )\n",
    "\n",
    "print(\"Evaluation: \")\n",
    "mse, acc = model.evaluate(testX, testy)\n",
    "print('mean_squared_error :', mse)\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDUINO SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE IF SAMPLES ARE IN A MATRIX FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"../input/arduino3a/AS3.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test.iloc[100,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Arduino Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZING TEST DATA AMPLITUDE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load the dataset and print the first 5 rows\n",
    "# prepare data for normalization\n",
    "values = test.values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "normalized = scaler.transform(values)\n",
    "\n",
    "dfnormalized = pd.DataFrame(normalized)\n",
    "dfnormalized.index = [x for x in range(1, len(dfnormalized.values)+1)]\n",
    "plt.plot(dfnormalized.iloc[30,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicing Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category= model.predict_classes(test) #not Normalized\n",
    "category= model.predict_classes(dfnormalized) #Normalized\n",
    "plt.plot(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean of Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE IF SAMPLES ARE IN A ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../input/arduinorow1a/test44.txt\", header=None)\n",
    "test = test.iloc[0,0:len(test.T)-1] # Remove last line cause it might be a Nan\n",
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZING TEST DATA AMPLITUDE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load the dataset and print the first 5 rows\n",
    "# prepare data for normalization\n",
    "values = test.values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "normalized = scaler.transform(values)\n",
    "normalized = pd.DataFrame(normalized.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING FOR ONE X\n",
    "#x=0\n",
    "#normalized = pd.DataFrame(normalized.T) ## CAUTION!!! needs to run only once \n",
    "#normtest=normalized.iloc[0, 0+x:187+x] \n",
    "#normtest=pd.DataFrame(normtest)\n",
    "#category = model.predict_classes(normtest.T)\n",
    "#category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= pd.DataFrame()\n",
    "category=category.dropna()\n",
    "lst_seq = np.arange(0,len(normalized.T)-190)\n",
    "for x in lst_seq:\n",
    "    normtest=normalized.iloc[0, 0+x:187+x] \n",
    "    normtest=pd.DataFrame(normtest)\n",
    "    category[x] = model.predict_classes(normtest.T)\n",
    "category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEAN OF CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(category.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT OF CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(category.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display frequency of each predicted category as evaluated by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.DataFrame(category)\n",
    "temp1= category.iloc[0,:].value_counts()\n",
    "print(\"Categories vs Value Count\")\n",
    "print(temp1)\n",
    "print(\"Categories vs Frequency\")\n",
    "print(temp1/(len(category.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NEW MODEL CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.kaggle.com/gregoiredc/arrhythmia-on-ecg-classification-using-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ed80d5250c96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m187\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m187\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "target_train=train_df[187]\n",
    "target_test=test_df[187]\n",
    "y_train=to_categorical(target_train)\n",
    "y_test=to_categorical(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.iloc[:,:186].values\n",
    "X_test=test_df.iloc[:,:186].values\n",
    "#for i in range(len(X_train)):\n",
    "#    X_train[i,:186]= add_gaussian_noise(X_train[i,:186])\n",
    "X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
    "X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(X_train,y_train,X_test,y_test):\n",
    "    \n",
    "\n",
    "    im_shape=(X_train.shape[1],1)\n",
    "    inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n",
    "    conv1_1=Convolution1D(64, (6), activation='relu', input_shape=im_shape)(inputs_cnn)\n",
    "    conv1_1=BatchNormalization()(conv1_1)\n",
    "    pool1=MaxPool1D(pool_size=(3), strides=(2), padding=\"same\")(conv1_1)\n",
    "    conv2_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool1)\n",
    "    conv2_1=BatchNormalization()(conv2_1)\n",
    "    pool2=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv2_1)\n",
    "    conv3_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool2)\n",
    "    conv3_1=BatchNormalization()(conv3_1)\n",
    "    pool3=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv3_1)\n",
    "    flatten=Flatten()(pool3)\n",
    "    dense_end1 = Dense(64, activation='relu')(flatten)\n",
    "    dense_end2 = Dense(32, activation='relu')(dense_end1)\n",
    "    main_output = Dense(5, activation='softmax', name='main_output')(dense_end2)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs= inputs_cnn, outputs=main_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "    history=model.fit(X_train, y_train,epochs=30,callbacks=callbacks, batch_size=32,validation_data=(X_test,y_test))\n",
    "    model.load_weights('best_model.h5')\n",
    "    return(model,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(history,X_test,y_test,model):\n",
    "    scores = model.evaluate((X_test),y_test, verbose=0)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    \n",
    "    print(history)\n",
    "    fig1, ax_acc = plt.subplots()\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model - Accuracy')\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    fig2, ax_loss = plt.subplots()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Model- Loss')\n",
    "    plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.show()\n",
    "    target_names=['0','1','2','3','4']\n",
    "    \n",
    "    y_true=[]\n",
    "    for element in y_test:\n",
    "        y_true.append(np.argmax(element))\n",
    "    prediction_proba=model.predict(X_test)\n",
    "    prediction=np.argmax(prediction_proba,axis=1)\n",
    "    cnf_matrix = confusion_matrix(y_true, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d0bc027793fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model,history=network(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e4dd497b4d79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(history,X_test,y_test,model)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "category= pd.DataFrame()\n",
    "category=category.dropna()\n",
    "lst_seq = np.arange(0,len(normalized.T)-190)\n",
    "for x in lst_seq:\n",
    "    temp=normalized.iloc[0,0+x:186+x]\n",
    "    temp=pd.DataFrame(temp) \n",
    "    temp=temp.values\n",
    "    temp=temp.reshape(1,186,1)\n",
    "    category=pd.DataFrame(model.predict(temp))\n",
    "    df = pd.DataFrame(category)\n",
    "    df1=df1.append(df)\n",
    "    \n",
    "category=df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean of each Catecory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=pd.DataFrame(category)\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1=category[0].mean()\n",
    "cat2=category[1].mean()\n",
    "cat3=category[2].mean()\n",
    "cat4=category[3].mean()\n",
    "cat5=category[4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MODEL RNN LSTM GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 USE IF SAMPLES ARE IN A ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../input/arduinorow1a/test44.txt\", header=None)\n",
    "test = test.iloc[0,0:len(test.T)-1] # Remove last line cause it might be a Nan\n",
    "test = pd.DataFrame(test)\n",
    "# NORMALIZING TEST DATA AMPLITUDE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load the dataset and print the first 5 rows\n",
    "# prepare data for normalization\n",
    "values = test.values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "normalized = scaler.transform(values)\n",
    "normalized = pd.DataFrame(normalized)\n",
    "normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "## https://www.hindawi.com/journals/jhe/2019/6320651/\n",
    "## https://www.mathworks.com/help/signal/examples/classify-ecg-signals-using-long-short-term-memory-networks.html\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-53cec0a96071>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1 https://www.kaggle.com/freddycoder/heartbeat-categorization\n",
    "# Separate features and targets\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print(\"--- X ---\")\n",
    "# X = mit_train_data.loc[:, mit_train_data.columns != 187]\n",
    "X = train_df.loc[:, mit_train_data.columns != 187]\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "\n",
    "print(\"--- Y ---\")\n",
    "# y = mit_train_data.loc[:, mit_train_data.columns == 187]\n",
    "y = train_df.loc[:, mit_train_data.columns == 187]\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(\"--- testX ---\")\n",
    "#testX = mit_test_data.loc[:, mit_test_data.columns != 187]\n",
    "testX = test_df.loc[:, mit_test_data.columns != 187]\n",
    "print(testX.head())\n",
    "print(testX.info())\n",
    "\n",
    "print(\"--- testy ---\")\n",
    "#testy = mit_test_data.loc[:, mit_test_data.columns == 187]\n",
    "testy = test_df.loc[:, mit_test_data.columns == 187]\n",
    "testy = to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "embedding_vecor_length = 187\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, embedding_vecor_length, input_length=187))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(X, y, validation_data=(testX, testy), epochs=3, batch_size=32)\n",
    "\n",
    "\n",
    "#Dropout is a powerful technique for combating overfitting in your LSTM models \n",
    "#model = Sequential()\n",
    "#model.add(Embedding(1000, embedding_vecor_length, input_length=187))\n",
    "#model.add(LSTM(50, dropout=0.001, recurrent_dropout=0.001))\n",
    "#model.add(Dense(5, activation='softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#print(model.summary())\n",
    "#history = model.fit(X, y, validation_data=(testX, testy), epochs=50, batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "## SAVE MODEL ##\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"1model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"1model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mse, acc = model.evaluate(testX, testy)\n",
    "print('mean_squared_error :', mse)\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# The history for the validation dataset is labeled test by convention as it is indeed a test dataset for the model.\n",
    "#The plots can provide an indication of useful things about the training of the model, such as:\n",
    "#*It’s speed of convergence over epochs (slope).\n",
    "#*Whether the model may have already converged (plateau of the line).\n",
    "#*Whether the mode may be over-learning the training data (inflection for validation line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Αccuracy and prediction scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(testX, batch_size=1000)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "\n",
    "print(classification_report(testy.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict category of Arduino sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= pd.DataFrame()\n",
    "category=category.dropna()\n",
    "lst_seq = np.arange(0,len(normalized.T)-190)\n",
    "for x in lst_seq:\n",
    "    normtest=normalized.iloc[0, 0+x:187+x] \n",
    "    normtest=pd.DataFrame(normtest)\n",
    "    category[x] = model.predict_classes(normtest.T)\n",
    "category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEAN OF CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(category.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT OF CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(category.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display frequency of each predicted category as evaluated by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.DataFrame(category)\n",
    "temp1= category.iloc[0,:].value_counts()\n",
    "print(\"Categories vs Value Count\")\n",
    "print(temp1)\n",
    "print(\"Categories vs Frequency\")\n",
    "print(temp1/(len(category.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"../working/model.json\", 'r')\n",
    "model_json = json_file.read() \n",
    "json_file.close()\n",
    "\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"../working/model.h5\")\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "#prediction = model.predict(x_test, batch_size=2048)[0].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
