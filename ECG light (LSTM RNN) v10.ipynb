{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Softmax, Add, Flatten, Activation# , Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  # DATA ACQUISITION *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"C:/Users/nisch/Desktop/ECG Categorization\\DATASET\\mitbih_test.csv\", header=None);\n",
    "train = pd.read_csv(\"C:/Users/nisch/Desktop/ECG Categorization\\DATASET\\mitbih_train.csv\", header=None);\n",
    "mit_train_data = train\n",
    "mit_test_data = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRODUCE BALANCED DATASET train_df , test_df *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a huge difference in the balanced of the classes.\n",
    "# Better choose the resample technique more than the class weights for the algorithms.\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_1=mit_train_data[mit_train_data[187]==1]\n",
    "df_2=mit_train_data[mit_train_data[187]==2]\n",
    "df_3=mit_train_data[mit_train_data[187]==3]\n",
    "df_4=mit_train_data[mit_train_data[187]==4]\n",
    "df_0=(mit_train_data[mit_train_data[187]==0]).sample(n=20000,random_state=42)\n",
    "\n",
    "df_1_upsample=resample(df_1,replace=True,n_samples=20000,random_state=123)\n",
    "df_2_upsample=resample(df_2,replace=True,n_samples=20000,random_state=124)\n",
    "df_3_upsample=resample(df_3,replace=True,n_samples=20000,random_state=125)\n",
    "df_4_upsample=resample(df_4,replace=True,n_samples=20000,random_state=126)\n",
    "\n",
    "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])\n",
    "\n",
    "\n",
    "df_11=mit_test_data[mit_train_data[187]==1]\n",
    "df_22=mit_test_data[mit_train_data[187]==2]\n",
    "df_33=mit_test_data[mit_train_data[187]==3]\n",
    "df_44=mit_test_data[mit_train_data[187]==4]\n",
    "df_00=(mit_test_data[mit_train_data[187]==0]).sample(n=20000,random_state=42)\n",
    "\n",
    "df_11_upsample=resample(df_1,replace=True,n_samples=20000,random_state=123)\n",
    "df_22_upsample=resample(df_2,replace=True,n_samples=20000,random_state=124)\n",
    "df_33_upsample=resample(df_3,replace=True,n_samples=20000,random_state=125)\n",
    "df_44_upsample=resample(df_4,replace=True,n_samples=20000,random_state=126)\n",
    "\n",
    "test_df=pd.concat([df_00,df_11_upsample,df_22_upsample,df_33_upsample,df_44_upsample])\n",
    "\n",
    "\n",
    "equilibre=train_df[187].value_counts()\n",
    "print(equilibre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ALL Train data\")\n",
    "print(\"Type\\tCount\")\n",
    "print((mit_train_data[187]).value_counts())\n",
    "print(\"-------------------------\")\n",
    "print(\"ALL Test data\")\n",
    "print(\"Type\\tCount\")\n",
    "print((mit_test_data[187]).value_counts())\n",
    "\n",
    "print(\"ALL Balanced Train data\")\n",
    "print(\"Type\\tCount\")\n",
    "print((train_df[187]).value_counts())\n",
    "print(\"-------------------------\")\n",
    "print(\"ALL Balanced Test data\")\n",
    "print(\"Type\\tCount\")\n",
    "print((train_df[187]).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE HOT Encoding *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for categorical target\n",
    "#Since we will be using neural networks for our classification model, \n",
    "#our output classes need to be turned into a numerical representation. We use one hot encoding (from sklearn package) to do this.\n",
    "\n",
    "\n",
    "\n",
    "#train_target = mit_train_data[187]\n",
    "#train_target = train_target.values.reshape(87554,1)\n",
    "train_target = train_df[187]\n",
    "train_target = train_target.values.reshape(100000,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#one hot encode train_target\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "# TODO: create a OneHotEncoder object, and fit it to all of X\n",
    "\n",
    "# 1. INSTANTIATE\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(train_target)\n",
    "\n",
    "# 3. Transform\n",
    "onehotlabels = enc.transform(train_target).toarray()\n",
    "onehotlabels.shape\n",
    "\n",
    "target = onehotlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ground truth labels from training df\n",
    "#train/test split\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = mit_train_data\n",
    "X = train_df\n",
    "X = X.drop(axis=1,columns=187)\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,target, test_size = 0.25, random_state = 36)\n",
    "X_train = np.asarray(X_train)\n",
    "X_valid = np.asarray(X_valid)\n",
    "Y_train = np.asarray(Y_train)\n",
    "Y_valid = np.asarray(Y_valid)\n",
    "\n",
    "#X_train.reshape((1, 2403, 187))\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid = np.expand_dims(X_valid, axis=2)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "# 2,403 training heartbeats and 802 validation heartbeats \n",
    "# for a 75:25 train-test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MODEL RNN LSTM GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 USE IF SAMPLES ARE IN A ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"C:/Users/nisch/Desktop/ECG Categorization/ARDUINO SAMPLES/Schetakis.txt\", header=None)\n",
    "test = test.iloc[0,0:len(test.T)-1] # Remove last line cause it might be a Nan\n",
    "test = pd.DataFrame(test)\n",
    "print(os.getcwd())\n",
    "# NORMALIZING TEST DATA AMPLITUDE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load the dataset and print the first 5 rows\n",
    "# prepare data for normalization\n",
    "values = test.values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "normalized = scaler.transform(values)\n",
    "normalized = pd.DataFrame(normalized)\n",
    "normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "## https://www.hindawi.com/journals/jhe/2019/6320651/\n",
    "## https://www.mathworks.com/help/signal/examples/classify-ecg-signals-using-long-short-term-memory-networks.html\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1 https://www.kaggle.com/freddycoder/heartbeat-categorization\n",
    "# Separate features and targets\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print(\"--- X ---\")\n",
    "# X = mit_train_data.loc[:, mit_train_data.columns != 187]\n",
    "X = train_df.loc[:, mit_train_data.columns != 187]\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "\n",
    "print(\"--- Y ---\")\n",
    "# y = mit_train_data.loc[:, mit_train_data.columns == 187]\n",
    "y = train_df.loc[:, mit_train_data.columns == 187]\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(\"--- testX ---\")\n",
    "#testX = mit_test_data.loc[:, mit_test_data.columns != 187]\n",
    "testX = test_df.loc[:, mit_test_data.columns != 187]\n",
    "print(testX.head())\n",
    "print(testX.info())\n",
    "\n",
    "print(\"--- testy ---\")\n",
    "#testy = mit_test_data.loc[:, mit_test_data.columns == 187]\n",
    "testy = test_df.loc[:, mit_test_data.columns == 187]\n",
    "testy = to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "embedding_vecor_length = 187\n",
    "model = Sequential()\n",
    "model.add(Embedding(150, embedding_vecor_length, input_length=187))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(X, y, validation_data=(testX, testy), epochs=5, batch_size=32)\n",
    "\n",
    "\n",
    "#Dropout is a powerful technique for combating overfitting in your LSTM models \n",
    "#model = Sequential()\n",
    "#model.add(Embedding(1000, embedding_vecor_length, input_length=187))\n",
    "#model.add(LSTM(50, dropout=0.001, recurrent_dropout=0.001))\n",
    "#model.add(Dense(5, activation='softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#print(model.summary())\n",
    "#history = model.fit(X, y, validation_data=(testX, testy), epochs=50, batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "## SAVE MODEL ##\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"1model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"1model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mse, acc = model.evaluate(testX, testy)\n",
    "print('mean_squared_error :', mse)\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# The history for the validation dataset is labeled test by convention as it is indeed a test dataset for the model.\n",
    "#The plots can provide an indication of useful things about the training of the model, such as:\n",
    "#*It’s speed of convergence over epochs (slope).\n",
    "#*Whether the model may have already converged (plateau of the line).\n",
    "#*Whether the mode may be over-learning the training data (inflection for validation line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Αccuracy and prediction scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(testX, batch_size=1000)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "\n",
    "print(classification_report(testy.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict category of Arduino sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= pd.DataFrame()\n",
    "category=category.dropna()\n",
    "lst_seq = np.arange(0,len(normalized.T)-190)\n",
    "for x in lst_seq:\n",
    "    normtest=normalized.iloc[0, 0+x:187+x] \n",
    "    normtest=pd.DataFrame(normtest)\n",
    "    category[x] = model.predict_classes(normtest.T)\n",
    "category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEAN OF CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(category.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT OF CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(category.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display frequency of each predicted category as evaluated by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.DataFrame(category)\n",
    "temp1= category.iloc[0,:].value_counts()\n",
    "print(\"Categories vs Value Count\")\n",
    "print(temp1)\n",
    "print(\"Categories vs Frequency\")\n",
    "print(temp1/(len(category.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"../working/model.json\", 'r')\n",
    "model_json = json_file.read() \n",
    "json_file.close()\n",
    "\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"../working/model.h5\")\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "#prediction = model.predict(x_test, batch_size=2048)[0].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
